## 线程的安全机制

#### 锁的相关概念：
1. 公平锁：多个现成按照申请锁的顺序去获取锁，现成会直接进入队列中排队，永远都是队列第一位才能获取锁。
   *优点：所有的线程都能得到资源，不会饿死在队列中。
   *缺点: 因为cpu需要一次唤醒阻塞队线程，开销会很大，影响吞吐量。
2. 非公平锁：多个线程去获取锁的时候，会直接去获取锁，如果获取不到，会进入等待队列。
   *优点: 相对于公平锁来说，cpu不必唤醒所有的线程，减少了cpu的开销，整体的吞吐量效率会高一点。
   *缺点: 会造成线程的饥饿，队列中的某个线程会长时间获取不到锁。
3. 可重入锁：一个线程如果持有锁，那么它可以再次进入线程获取锁的时候，不需要等待。不会因为之前获取过锁没有释放而造成死锁。
### 1.使用synchronized
**synchronized的锁定范围**
1. 对象锁
    指多个线程调用同一对象的同步方法会阻塞 ，调用不同对象的同步方法不会阻塞
    - 修饰在普通方法上
    - 修饰在代码块，括号后面是类对象
2. 类锁
    指多个线程调用时候，不管是不是同一对象，都会被阻塞。
    - 修饰在静态方法上
    - 修饰在代码块，括号后面是类的class对象

**synchronized版本对比**
- 1.6之前，synchronized是重量级锁，是基于底层的mutex lock实现的，每次获取锁，释放锁都会带来**上下文切换**，从而增加了系统性能的开销，在锁竞争激烈的时候性能会非常差。
- 1.6以后，synchronized锁进行了优化，引入了偏向锁，轻量级锁，最后升级为重量级锁。通过竞争的激烈程度来自动选择合适的锁，通过java对象头存储锁的信息，避免一开始就使用重量级锁，以及减少锁竞争带来的上下文切换，从而提高性能。

>什么是上下文的切换
> 时间片决定了一个线程可以占用处理器运行的时长。当一个线程的时间片用完，或者因为自身的原因被迫停止运行，另一个线程会被操作系统选中进入处理器。
> 以上的过程中，一个线程被剥夺使用权或者退出，即切出。另一个线程被处理器选中进入处理器开始或者继续运行，即切入。切入切出的流程中，操作系统保存或者恢复响应的进度信息，即上下文。整个流程便是上下文的切换流程。

**synchronized底层原理**
- synchronized如果修饰的是代码块则会插入字节码指令**monitor enter**和**monitor exit**，一般会生成这两个monitor指令会自动解锁，因为有异常情况也需要解锁，不然就会死锁的。
synchronized深入到jvm底层是和对象头息息相关的。
#### 对象的组成
*1. 对象头*
- markWord 标记字段 : 存储哈希码，对象年龄，锁信息（锁标志位，偏向线程id，偏向时间戳等)。 不同的对象头中markWord的存储结构是不同的。
- klass pointer 类型指针：当前对象类的元数据指针，虚拟机通过这个指针来指定这个对象是那个类的实例。（klass：jvm中的数据结构，存储类的信息包括常量池，字段，方法等。存放在方法区）
- 数组长度： 只有数组对象才有
*2. 实例数据*
- 程序代码里面所定义的各种类型的字段内容，包括从父类继承下来的。
*3. 对象填充*
- 仅仅起到占位符的作用，若对象实例数据没有对齐的话，会通过对其填充来补全。

#### 对象头详细
![avatar](pic/32.png)

![avatar](pic/64.png)

#### 锁状态
![avatar](pic/锁状态.png)

####1.无锁
- 对象头的25bit用来存储对象的hashCode；4bit用来存储对象的分代年龄；1bit存储是否偏向锁的锁标识位，当前为否；2bit用来存放锁标识位01。
####2.偏向锁
- 对象头的25bit分为两段，23bit用来存线程id，2bit用来存epoch；4bit用来存对象的分代年龄；1bit存储偏向锁的锁表示为，当前位是；2bit用来存放锁表示位01。
> 为什么有偏向锁
* 在实际的生产环境中，一段时间内同步的方法会被同一个线程访问。如果使用轻量级锁，每次调用同步方法，都要通过一次cas来申请锁，通过一次cas来释放锁。
这种cas毕竟会占用cpu的资源（cas指的是轻量锁使用cas将markWord更新为指向锁记录的指针，所以针对此场景进行了优化，当线程A调用同步方法的指向后，不会释放锁，
再次进入的时候，不需要重新获取锁。只有在其他线程的进入的时候，才会重新获取。
> 偏向锁原理
* 如果当前对象支持偏向锁，就会通过cas操作，将当前的线程地址记录到*markWord*中，并且标记字段的后三位设置为*101*。
之后如果有线程来请求这把锁，只需要判断*markWord*最后的三位是不是101，以及是否指向当前的线程地址。同时还需要判断*epoch*值是否和锁对象中的*epoch*一致。如果都一致，说明当前线程持有偏向锁。

>线程已经偏向某个线程必须满足的条件
> *markWord中的threadId是线程的ID。
> *markWord中的epoch必须和类的epoch相等。

* 如果下一个线程要获取锁的时候，发现对象是可偏向的，但是偏向的线程id和当前获取的现成id不同，说明这个偏向锁偏向于其他线程，需要撤销偏向锁模式。*（注意这里是撤销，不是解锁，因为现在需要将偏向锁的模式进行膨胀）*
>偏向锁的撤销
* 偏向锁的撤销是一个很特殊的操作，为了执行撤销的操作，需要等待全局安全点（safe point），此时间点所有的工作线程都停止了字节码的执行。在进入膨胀流程的时候，会判断偏向锁的现成是否正在执行同步代码块，
如果持有偏向锁的线程已经执行完了，就应该将偏向锁对象的mark work置为无锁的状态。但是，如果还没有执行完，应该直接将偏向锁膨胀为轻量锁。后面就是走轻量锁的逻辑了。

>为什么要等待全局安全点时候才能进行膨胀？
* 首先这个时间点所有的工作线程都停止了字节码的执行。其次就是线程A在占用偏向锁执行同步代码块的时候，线程B也要抢占偏向锁，证明存在多线程竞争，线程B就需要将这个偏向锁进行膨胀，这也就意味这个线程B需要操作线程A的线程栈。
所以需要找一个等待的时间点，让线程B来操作，这个时间点就是*stop the world*，没有字节码执行的时候。

>偏向锁膨胀的具体流程？
* 当线程A在都听过cas方式获取偏向锁的时候，会在线程A的栈帧中建立一个锁记录（lock Record）。
* 如果线程B在进行抢占，这时候需要撤销偏向锁的模式，在全局安全点的时候，如果发现了A有偏向锁，但是还没有执行完同步代码块，B会遍历A所有的栈帧，查找到所有与当前偏向锁对象相关的锁记录，*修改这些锁的记录为轻量锁的内容*
  好，然后把最老的（oldest，栈帧）记录的记录写到锁对象的markWord中，就好像从来都没有使用过偏向锁。
* 之所以要最好的，是要因为A可能重入的很多次，则栈帧中记录的是个null，所以需要把最老的所记录的指针写到对象的markWord中，从而完成了B的锁膨胀流程。

####3.轻量锁

>为什么有轻量级锁?
* jdk1.6之前是没有轻量以及偏向锁的特征的。*多个线程在不同的时间段来请求用一把锁，根本不需要阻塞线程。连monitor对象都不需要，所以就引入了轻量级锁的概念，避免系统调用，减少开销。*
1. 为了解决synchronized性能效率低的问题。之前synchronized在monitor的模式下，每次进入synchronized都要创建一个monitorObject对象。在真实的生产环境下，并不是一直处于多线程竞争的，大多数情况下回先访问同步代码块
，线程a访问完毕以后，线程B才会访问同步代码块，他们之前的访问类似交替访问，或许只有轻微的竞争甚至没有竞争问题。这时候使用monitor显得大材小用，浪费空间。
2. 重量级锁会设计到用户态切换和内核态进行线程的阻塞和唤醒操作，然后再切换到用户态。这种上下文的切换给系统的并发性能带来了很大的压力，有时候锁状态时间段，为了短时间去挂起和恢复是不值得的。
所以在申请锁资源的时候通过一个cas操作即可获取，释放锁资源时候也是通过一个cas操作即可完成，cas是一个乐观锁的实现，开销显然比互斥要小的多。

>轻量锁的加锁过程
1. 首先在进入同步代码块的线程会创建一个锁记录（lock record）。
2. 然后拷贝锁对象的markWord到当前栈帧的锁记录中（lock record）。
3. 拷贝完成后，尝试cas将markWord更新为当前记录的指针，并将lock record中owner指向对象的 mark word。若更新出成功，当前线程获取了锁，锁标识位00，表示进入了轻量锁。
4. 如果更新失败了，说明现在是有两个以上的线程在竞争，因为两个必然会有一个成功，一个失败。这时候jvm会检查轻量锁的指针是否指向当前某个线程的锁记录，如果是，表示拥有轻量锁，是重入锁的特征正常同步代码块。如果不是，表示还有其他线程，存在竞争。
5. 存在两个以上的线程竞争，轻量锁会立即膨胀，变为重量锁。如果升级到重量锁之后，还没有获取到锁，会进行一定程度的自旋争抢锁（JDK8，源码synchronizer.cpp中），如果还没获取到，会进入线程中阻塞。

>轻量锁的解锁过程
1. 在没有竞争的时候，当持有轻量锁的线程执行完同步代码块以后，会通过一次cas将当前操作栈帧中的lock record重置会之前轻量锁对象的markWord中，若成功则表示释放完成。 
2. 但是如果有其他线程在竞争该轻量锁，而且其他竞争的线程在多次自旋后依然无法对象头的指针，那么就会将这个轻量锁膨胀为重量锁。竞争的线程会修改Mark Word的锁标识为重量锁的10，然后这个竞争线程就会被阻塞。 
3. 在持有这个轻量锁的线程执行完同步方法后，在通过CAS重置轻量锁的对象头的时候,发现自己的Lock Record和轻量锁的对象头不同，因为轻量锁的锁标识已经被其他线程的修改为重量锁标识，所以在释放锁的同时，会唤醒正在等待该轻量锁的而阻塞的线程。

####4.重量锁
>ObjectMonitor内置锁的概念*缺图*
- CXQ队列（_cxq）：竞争队列，所有请求锁的线程首先会被放在这个队列中（单向链接 
   - 并不是一个真正的queue，是一个临界资源。有node及其next指针逻辑构成，是一个后进先出（LIFO）的队列（栈）。 
   - 【每次新加入Node时都会在队头进行，通过CAS改变第一个节点的的指针为新增节点（新线程），同时设置新增节点的next指向后续节点。通过这种方式减轻了队列取数据时的争用问题。而且该结构是个Lock-Free的队列无锁队列（实际上就是通过CAS不断的尝试来实现的）。 】
- EntryList：CXQ队列中有资格成为候选资源的线程会被移动到该队列中 
  - 获得锁得到执行权力的Owner线程在释放锁时会从CXQ队列或EntryList中挑选一个线程唤醒，到底唤醒哪个取决于Monitor的策略
- OnDeck：任何时刻最多只能有一个线程正在竞争锁，该线程称为OnDeck
- Owner：获得锁的线程称为Owner。初始时为NULL，当有线程占有该monitor的锁的时候，Owner标记为该线程的唯一标识，当线程释放monitor时，Owner又恢复为NULL。
- WaitSet：如果Owner线程被wait方法阻塞，则转移到WaitSet队列
  - 如果Owner线程被wait方法阻塞，则转移到WaitSet队列。当wait的线程在某个时刻被notify/notifyAll之后，会将对应的ObjectWaiter从WaitSet移动到EntryList或CXQ队列中
>重量锁的加锁过程
1. 线程先尝试讲moniter对象的_owner通过cas指向改线程，要是成功了，_recursions更新为1，表示为重入锁。若失败便会自旋。
2. 自旋若没有获取到锁，会将当前线程包装这个objectWait对象，插入到_cxq队列的头部，并继续进行cas尝试获取锁。
3. 若还是失败，便会查看对象的__Responsible的指针是不是null，如果这个指针为null，代表之前对象锁没有等待线程。也就说明当前线程为第一个等待线程。
这时候会通过cas将_Responsible指向自己。接下来便会指向退避算法，进行一个短时间的阻塞等待。 //这个算法很简单，第一次等待1 ms，第二次等待8 ms，第三次等待64 ms，以此类推，直到达到等待时长的上限 1000 ms，也就是说在synchronize在一个对象锁上的线程，如果它是第一个等待线程的话，那么它会不停滴休眠、检查锁，休眠的时间由刚才的退避算法指定。如果当前线程不是第一个等待线程，那么只能执行无限期的休眠，一直等待对象锁的exit函数执行唤醒才行；

>重量锁的解锁过程
1. 如果recursions不是0，说明是重量锁，直接--便可以。

### 2.使用显示锁-ReentrantLock
> synchronized是一种隐式锁，ReentrantLock是一种显示锁，需要自己进行加锁解锁，更加灵活。重入锁，即一个线程可以反复的进入这种锁。
* 当同一个线程多次获取锁的时候，只有和释放锁的次数相等才会正常进入；若获取次数小于释放次数，那么会抛出异常（IllegalMonitorStateException);
若获取次数大于释放次数，那么线程无法进入。

#### ReentrantLock中几个重要的方法：
  * lock()：获取锁，如果锁已经被占用，则等待。
  * lockInterruptibly()：获得锁，优先响应中断。
  * tryLock()：尝试获取锁，如果成功，返回true；失败返回false。改方法不等待，立即返回。
  * tryLock(long time, TimeUnit unit)：在给定时间内尝试获取锁。
  * unLock：释放锁
  * ReentrantLock(boolean fair)：构造方法，设置是否为公平锁。
####公平锁与非公平锁
  * 公平锁：不会有饥饿的现象，但是需要一个维护有序的队列，实现成本高，性能低下。
    * 在获取锁的过程中，如果同时还有另一个线程来获取，当发现自己不是对首的时候，会排到队尾，由对首获取锁。
  * 非公平锁
    * 在获取锁的过程中，如果同时还有另一个线程来获取，有可能会直接获取锁。
####ReentrantLock的主要实现：
  * 原子状态。 原子状态使用CAS操作，来存储当前锁的状态，判断锁是否已经被别的线程持有了。
  * 等待队列。 等待队列使用AQS（使用一个FIFO队列表示排队等待锁的的线程，其头结点称为哨兵'哨兵节点'，它不与任何线程关联；其余节点与等待线程关联，每个节点维护一个等待的状态）。
所有没有请求到锁的线程，会进入等待队列进行等待。待有线程释放锁以后，系统就能从等待队列中唤醒一个线程继续工作了。
  * 阻塞原语park()和unPark()，用于挂起和恢复线程。没有得到锁的线程会被挂起。

![avatar](pic/ReentrantLock.png)

#####与condition的配合
1. 重点方法：
   1. await() 线程等待，同事释放锁，当其他线程使用signal方法或使用signalAll()方法时候，线程会重新获取锁，并继续执行。
   2. signal()和signalAll()方法唤醒一个/全部等待中的线程。
2. ArrayBlockQueue内部使用
   - （仅写了condition的相关方法）
```java
import java.util.concurrent.locks.Condition;

class test {
    ReentrantLock lock = new ReentrantLock(fair);
    Condition condition = lock.newCondition();  // 生成一个与lock绑定的condition
    // put方法
    public void put(E e) {
        lock.lockInterruptibly();   //获取锁 进行同步
        if(true){    //队列已经满了
            condition.await();
        }else{
            condition.signal(); // 不满进行添加
        }
    }
}
```
### 3.使用volatile
#### 内存模型（JMM）
1. 原子性
   - 原子性指一个操作是不可以中断的，要么全部成功，要么全部失败。
2. 可见性
   - 指的是当一个线程修改了某个共享变量的值得时候，其他线程是否能立即知道这个修改。
3. 有序性
   - 程序的执行有先后。为了编译器和处理器的效率，JMM进行了执行重排。
   - 指令执行分为以下几步:
     - 取指IF
     - 译码和取寄存器数ID
     - 执行或者有效地址计算EX
     - 存储器访问MEM
     - 写回WB


![avatar](pic/jmm.png)
#####volatile相关
1. volatile保证的*可见性*和*有序性*，不能保证原子性。
2. volatile在执行写操作后，jmm会把工作内存的最新变量强制刷新到主内存。
3. volatile写操作会使其他的线程中的缓存无效

### 4.使用原子变量和cas
*CAS是JAVA并发包的基础，基于它可以实现更高效，乐观，非阻塞的数据结构和算法，也是并发包中锁，同步工具，和各种容器的基础。*
原子变量的基础是CAS,一般的计算机系统都在硬件层次上直接支持CAS指令。**通过循环CAS的方式实现原子更新是一种重要的思维。**

####CAS
CAS是(compare and swap),就是比较交换。
CAS操作包含三个操作数 【内存数值（V）、原值（A）和新值（B）】。
更新前会获取内存数值作为原值，更新时判断内存地址里面的值和原值是一样的，那么就将内存里面的值更新成B。
如果在第一轮循环中，a线程获取地址里面的值被b线程修改了，那么a线程需要自旋，重新获取内存位置的值,再比较更新,如果一直比较不相等,就会一直循环cas.比较消耗cpu.
>CAS乐观锁
>>java.util.concurrent.atomic.AtomicLong源码中的自增getAndIncrement()方法：AtomicInteger的compareAndSet(int expect, int update)方法实际是调用的Unsafe类

####CAS优缺点
优点 : 对比悲观锁性能上有很大的提高
缺点 :  
1. 存在ABA的问题.把原内存地址的值由A改成B,再改成A.此时cas无法判断.需要另外加版本号来区分。
2. 循环cas.可能会花费大量时间循环,比较浪费CPU。

### 5.写时复制
线程安全的问题，是因为多个线程并发读写同一个对象。如果每个线程读写的对象都是不同的，或者如果共享访问的对象是只读的，不能修改，那也就不存在线程安全的问题了。
**未完待续**
### 6.使用threadLocal
threadLocal：只有当前线程可以访问数据。
####实现原理
1. set方法 
   - 首先获取当前线程对象，通过getMap拿出来线程的ThreadLocalMap。并将值存入到ThreadLocalMap中。其中key就是ThreadLocal当前的像，value就是需要的值。而map本身就保存了自己的"局部变量"。
```java
class thread{
    public void set(T value){
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if(map!=null){
            map.set(this, value);
        }else{
            creatMap(t,value);
        }
    }
}
```
2. get方法
   - get方法就是先获取当前线程的ThreadLocal对象，然后通过将自己作为key取得内部的实际数据。
```java
class thread{
  public T get(){
      Thread thread = Thread.currentThread();
      ThreadLocalMap map = getMap(t);
      if(map!=null){
        ThreadLocalMap.Entry e = map.getEntry(this);
        if(e!=null){
            return (T)e.getValue();
        }
      }
  }
}
```

3. **ThreadLockMap是一个类似hashMapde的东西，更确定来说是类似WeakHashMap**，它的实现使用了弱引用。在垃圾回收的时候，java虚拟机发现了弱引用就会立即回收。
ThreadLocalMap内部由一系列Entry构成，每个Entry都是WeakReference<ThreadLocal>.

```java
import java.lang.ref.WeakReference;

static class Entry extends WeakReference<ThreadLocal>{
    Entry(ThreadLocal k, Object v){
        super(k);
        value = v;
    }
}
```
这里的参数ke就是map的key，v就是map的value，其中k也是ThreadLocal实例，作为弱引用的使用。
因此，虽然这里使用ThreadLocal作为Map的key，但实际上，他并不是真的持有ThreadLocal的引用。而是当TreadLocal的外部强引用被回收的时候，其key会变成null.当系统进行ThreadLocalMap清理的时候，就会将垃圾数据回收了。

####ThreadLcoak容易造成内存泄漏的地方
1. ThreadLocal本身对象泄漏
   - 使用的时候，会将其本身存储到Thread类的`ThreadLocal.ThreadLocalMap threadLocals`属性中。使用完ThreadLocal对象之后，手工设置对象为空null，通过GC是会被回收调的。这个是JDK本身来保证了。因为Map中元素使用了弱引用存储。
2. ThreadLocalMap中的Entry造成内存泄漏
   - 如果只是简单的将Entry改成弱引用，还是会有Value值的内存泄露，因为ThreadLocalMap中还一直维护着一个Entry对象，需要在ThreadLocal=null的时候，主动去remove，才能做到真正的全部回收。
- 如果我们不主动的清理，则可能会内存常驻，也可能会被清理掉： 
  - ThreadLocal在get和set的时候会主动去清理一下ThreadLocalMap中key=null的Entry对象。 
  - 在get的时候，如果命中到则直接返回，如果没有命中到则调用getEntryAfterMiss进行内存清理工作并重新rehash。 
  - 在set的时候后，如果命令的元素key位空，则会主动的替换掉，也可能会调用cleanSomeSlots方法完成内存清理工作并重新rehash。 

#### ThreadLocal对性能有什么帮助
- 为每个线程分配一个独立的对象，对系统性能是有帮助的，但是要取决于共享对象的内部逻辑。如果共享对象对于竞争的处理容易引起性能的损失，还是应该考虑应该使用ThreadLocal为每个线程分配单独的对象、
- 经典案例：多线程下产生随机数。

## 线程的协作机制
### wait/notify
### 显示条件
### 线程的中断
### 协作工具类
### 阻塞队列
### future/ futureTask

## 容器类
### 写时复制的list和set
### concurrentHashMap
### 各种队列


## 任务执行服务
### 线程池
#### 线程的创建
1. 继承thread
2. 实现runnable接口
#### 线程的状态变化

### 定时任务

###部分参考
- 锁相关 
https://tech.meituan.com/2018/11/15/java-lock.html
- volatile 
https://www.cnblogs.com/hanease/p/15864913.html

